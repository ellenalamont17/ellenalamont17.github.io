{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Larger and more frequent wildfires are cause for concern\n",
    "\n",
    "Over the last few decades, wildfires have increased in both number and size across North America [(Schoennagel et al., 2017)](https://www.pnas.org/doi/abs/10.1073/pnas.1617464114). Regions such as the western United States have been hit particularly hard, where the problem is exacerbated by changes in climate, vegetation, and landuse. Not only are more swaths of land burning each year, but with urban sprawl forcing more people to build homes at and beyond the wildland-urban interface, increasing populations are put at risk of disaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages\n",
    "import os                           # Reproducible file names\n",
    "import warnings                     # View warnings\n",
    "\n",
    "# Import third part packages\n",
    "import cartopy.crs as ccrs          # Cartographic projections\n",
    "import earthpy as et                # File organization\n",
    "import geopandas as gpd             # Enables work in geodataframes\n",
    "import geoviews as gv               # Enables work with geographic data\n",
    "import holoviews as hv              # For use with interactive plotting\n",
    "import hvplot.pandas                # Plotting maps and plots\n",
    "import pandas as pd                 # Work with dataframes\n",
    "import pyogrio                       # Help with import of geodatabase\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native American Areas Dataset Description\n",
    "\n",
    "The United States Geologic Survey (USGS) maintains a [National Boundary Dataset (NBD)](https://www.sciencebase.gov/catalog/item/5eaa545982cefae35a22231f) covering all 50 states and U.S. territories. The NBD includes boundaries including, but not limited to, political boundaries, national land holdings, U.S. Bureau holdings, military areas, and reserves managed by native communities. The Native American Area boundaries dataset within the NBD are derived from the [U.S. Census Bureau](https://www.census.gov/geographies/mapping-files/time-series/geo/cartographic-boundary.html). These boundaries come from the Bureau's 2017 Boundary and Annexation Survey and is a combination of two datasets that include the American Indian/Alaska Native/ Native Hawaiian Areas national data and the Alaska Native Regional Corporation state-based data. Combined, these two datasets capture federally recognized American Indian reservations and off-reservation trust land areas, state-recognized American Indian reservations, Hawaiian homelands, and 12 Alaska Native Regional Corporations.\n",
    "\n",
    "**Data Citation:**\n",
    "U.S. Geological Survey, National Geospatial Technical Operations Center, 2023, National Boundary Dataset (NBD), Native American Areas - [USGS National Map Downloadable Data Collection](https://www.sciencebase.gov/catalog/item/4f70b219e4b058caae3f8e19): U.S. Geological Survey, Reston, Virginia. Published 08/28/2023. Accessed 10/18/2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download national boundary data from the NBD Website\n",
    "# Data is a geodatabase of national boundaries from the entire nation\n",
    "# Note, to download large data, may need to change machine type of codespace\n",
    "nbd_url = (\n",
    "    \"https://prd-tnm.s3.amazonaws.com/StagedProducts/GovtUnit/National/GDB\"\n",
    "    \"/GovernmentUnits_National_GDB.zip\")\n",
    "\n",
    "nbd_dir = et.data.get_data(url=nbd_url)    # Path to downloaded file directory\n",
    "nbd_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 2-digit HU layer\n",
    "# Call the GDB file\n",
    "wbd_path = os.path.join(wbd_dir, 'WBD_National_GDB.gdb')\n",
    "\n",
    "# Read in the GDB and layer of interest (regional watersheds - HU2)\n",
    "wbd_hu2_gdf = gpd.read_file(wbd_path, layer='WBDHU2', from_disk=True)\n",
    "wbd_hu2_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test plot to demonstrate successful import of data\n",
    "\n",
    "# wbd_hu2_gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wildfire Dataset Description\n",
    "\n",
    "The wildfire data used in this analysis comes from the [USDA's wildfire occurance data for the United States, 1992-2020](https://www.fs.usda.gov/rds/archive/Catalog/RDS-2013-0009.6). This is the fifth version of the dataset and was generated from reporting systems of federal, state, and local fire organizations. Wildfire occurences are reported from 1992-2020 and include 2.3 million wildfire records. \n",
    "\n",
    "**Data Citation:**\n",
    "Short, Karen C. 2022. Spatial wildfire occurrence data for the United States, 1992-2020 [FPA_FOD_20221014]. 6th Edition. Fort Collins, CO: Forest Service Research Data Archive. https://doi.org/10.2737/RDS-2013-0009.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download wildfire occurance data from geodatabase\n",
    "\n",
    "fire_url = (\n",
    "    \"https://www.fs.usda.gov/rds/archive/products/RDS-2013-0009.6\"\n",
    "    \"/RDS-2013-0009.6_Data_Format2_GDB.zip\"\n",
    ")\n",
    "\n",
    "fire_dir = et.data.get_data(url=fire_url)   # Path to downloaded fire directory\n",
    "fire_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import fires layer from geodatabase (cashing data)\n",
    "# Put import in an if statement to check if data already downloaded\n",
    "fire_path = os.path.join(fire_dir, 'Data','FPA_FOD_20221014.gdb')\n",
    "if not 'fire_gdf' in globals():\n",
    "    print('fire_gdf does not exist. Loading...')\n",
    "    fire_gdf = pyogrio.read_dataframe(fire_path, layer='Fires')\n",
    "\n",
    "fire_gdf.head()                     # Prints only first few lines of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the data (Lat/Long already assigned to geometry)\n",
    "# Create an updated geodatabase, populating specific variables\n",
    "# [[]] Two sets, one to search and one to define a list\n",
    "fire_clean_gdf = (\n",
    "    fire_gdf\n",
    "    [['FOD_ID', 'DISCOVERY_DATE', 'FIRE_SIZE', 'geometry']]\n",
    "    .set_index('FOD_ID')\n",
    ")\n",
    "\n",
    "# Convert the existing date to a datetime format\n",
    "fire_clean_gdf.DISCOVERY_DATE = pd.to_datetime(fire_clean_gdf.DISCOVERY_DATE)\n",
    "\n",
    "# Reproject dataframe to match the CRS of watershed boundary\n",
    "print('Geodetic CRS before reprojection: ' + str(fire_clean_gdf.crs))\n",
    "fire_clean_gdf = fire_clean_gdf.to_crs(wbd_hu2_gdf.crs)\n",
    "print('Geodetic CRS after reprojection: ' + str(fire_clean_gdf.crs))\n",
    "\n",
    "fire_clean_gdf                  # Use .info() to see data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatially join the watershed with the fire history geodataframes\n",
    "fire_region_gdf = (\n",
    "    wbd_hu2_gdf[['name', 'geometry']]\n",
    "    .sjoin(fire_clean_gdf, how='inner', predicate='intersects')\n",
    ")\n",
    "\n",
    "# Calculate max fire size for each year in watershed combination\n",
    "fire_region_gdf = (fire_region_gdf\n",
    "    .groupby(['name', fire_region_gdf.DISCOVERY_DATE.dt.year])\n",
    "    .agg(\n",
    "        max_fire_size=('FIRE_SIZE','max'),      # New name = old, how\n",
    "        num_fires=('index_right', 'count'))     # New name = old, how\n",
    ")\n",
    "\n",
    "print('Total number of fires: ' + str(fire_region_gdf.num_fires.sum()))\n",
    "fire_region_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the area of each watershed (use Albers Equal Area Projection)\n",
    "wbd_hu2_gdf['area_ha'] = (        # Add an area column to gdf\n",
    "    wbd_hu2_gdf.to_crs(9822)      # Convert new temp gdf to Albers epsg\n",
    "    .area/10000/1000000           # Calculate the watershed area (millions ha)\n",
    ")                                 # Note 1 hectare is 10,000 sq.m.\n",
    "\n",
    "# Calculate total number of fires in each watershed region\n",
    "fire_count_df = (fire_region_gdf  # Note that this is a regualar dataframe\n",
    "    .reset_index()                # Reset because name is currently in index\n",
    "    [['name', 'num_fires']]\n",
    "    .groupby('name')              # Group by the name of the region\n",
    "    .sum()                        # Sum of the number of fires \n",
    ")\n",
    "fire_density_gdf=(wbd_hu2_gdf     # Note that this will be a geodataframe\n",
    "    .set_index('name')\n",
    "    .join(fire_count_df)          # Join wbd to fire_density gdf\n",
    "    [['num_fires', 'area_ha', 'geometry']] # Add area and geomety back in\n",
    ")\n",
    "\n",
    "# Calculate fire density (number of fires per area)\n",
    "fire_density_gdf['fire_density_per_ha'] = (\n",
    "    fire_density_gdf.num_fires / fire_density_gdf.area_ha\n",
    ")\n",
    "\n",
    "# Print the index\n",
    "fire_density_gdf.fire_density_per_ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set values for ylabels and titles\n",
    "labels = pd.DataFrame(dict(\n",
    "    column_name = ['max_fire_size', 'num_fires'],\n",
    "    ylabel = ['Fire Size (million ha)', 'Number of Fires'],\n",
    "    title = ['Largest fire on record in the region', \n",
    "             'Total number of fires in the region']))\n",
    "\n",
    "def fire_plot(region_name, df=fire_region_gdf, labels=labels):\n",
    "    \"\"\"\n",
    "    Create a multi-panel plot for a region\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    region_name : str\n",
    "      The name of the region to generate a plot for. Must exists \n",
    "      in the 'name' index of df.\n",
    "    df : pd.DataFrame\n",
    "      The dataframe with the data to plot. Columns much match\n",
    "      an item in labels.column_name to be plotted\n",
    "    labels : pd.DataFrame\n",
    "      Plot labels. Must have a 'column_name', 'ylabel', and 'title'\n",
    "      columns with str values. Each row will be a subplot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    plot : hv.core.layout.Layout\n",
    "      A holoviews plot layout or similar. For use with hv.DynamicMap.\n",
    "    \"\"\"\n",
    "    # Generate a subplot for each row in the labels\n",
    "    subplots = []\n",
    "    # Iterate through the labels row by row (labels is a gdf)\n",
    "    for i, labs in labels.iterrows():\n",
    "        # Create subplot (for each region name row in gdf, create an hvplot)\n",
    "        subplot = (\n",
    "            df.xs(region_name, level='name')  # Look for name in name index\n",
    "            [[labs.column_name]]              # Take column name in labels gdf\n",
    "            .hvplot(\n",
    "                xlabel='Year', ylabel=labs.ylabel,\n",
    "                title=labs.title,\n",
    "                width=1000,                   # Set plot width\n",
    "                color='red', size=2           # Set line color and width\n",
    "            ))\n",
    "        subplots.append(subplot)              # Accumulate subplots in a list\n",
    "\n",
    "    # Stack the subplots vertically\n",
    "    plot = hv.Layout(subplots).cols(1)        # Use holoview, combine subplots\n",
    "    return plot\n",
    "\n",
    "# Create a dropdown menu to switch between regions\n",
    "(\n",
    "    hv.DynamicMap(\n",
    "        # The plotting function for the two-panel fire history\n",
    "        fire_plot,\n",
    "        # Define the dimension for the dropdown\n",
    "        kdims=[('region', 'Region')])         # (name of index, label name)\n",
    "    # Add the explicit indexing - region names as a bokeh dimension\n",
    "    .redim.values(region=fire_region_gdf.reset_index().name)\n",
    ")\n",
    "\n",
    "# region = input('What do you want to use?')    # Allows user to choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify the gdf geometries\n",
    "fire_density_gdf.geometry = (\n",
    "    fire_density_gdf.geometry.simplify(tolerance=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chloropleth map of fire density (geoviews polygons geometry)\n",
    "poly_plot = (\n",
    "    gv.Polygons(fire_density_gdf            # Use Geoviews polygon geometry\n",
    "                .drop(                      # Remove Alaska and Hawaii data\n",
    "                    ['Alaska Region', 'Hawaii Region'],\n",
    "                      axis='rows')\n",
    "                .reset_index()              # Reset index to extract 'name'\n",
    "                .dropna()                   # Remove NAN values\n",
    "                [['fire_density_per_ha', 'geometry']])\n",
    "    .opts(                                  # Set plotting options\n",
    "        width=1000, height=600,\n",
    "        colorbar=True, color='fire_density',\n",
    "        cmap='plasma', line_color='white',\n",
    "        xaxis='bare', yaxis='bare', tools=['hover']\n",
    "    )\n",
    ")\n",
    "((gv.tile_sources.OSM * poly_plot).opts(\n",
    "    data_aspect=1,\n",
    "    # projection=ccrs.PlateCarree(central_longitude=-121))\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
