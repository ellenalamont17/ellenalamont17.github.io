{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Describe the analysis and why useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages\n",
    "import os                           # Reproducible file names\n",
    "import warnings                     # View warnings\n",
    "\n",
    "# Import third part packages\n",
    "import earthpy as et                # File organization\n",
    "import geopandas as gpd             # Enables work in geodataframes\n",
    "import geoviews as gv               # Enables work with geographic data\n",
    "import holoviews as hv              # For use with interactive plotting\n",
    "import hvplot.pandas                # Plotting maps and plots\n",
    "import pandas as pd                 # Work with dataframes\n",
    "import pyogrio                       # Help with import of geodatabase\n",
    "\n",
    "# warning.simplefilter('ignore')    # Suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watershed Dataset Description\n",
    "\n",
    "The watershed data used in this analysis comes from the [USGS Watershed Boundary Dataset (WBD)](https://www.usgs.gov/national-hydrography/watershed-boundary-dataset) for the United States. All watersheds in this dataset have gauges for stream monitoring. The data used herein are the **HUC-2 Watersheds (Regional Scale)**. \n",
    "\n",
    "Describe the dataset and add citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download watershed data from the WBD Website\n",
    "# Data is a geodatabase of watersheds from the entire nation\n",
    "# Note, to download large data, may need to change machine type of codespace\n",
    "wbd_url = (\n",
    "    \"https://prd-tnm.s3.amazonaws.com/StagedProducts/Hydrography/WBD\"\n",
    "    \"/National/GDB/WBD_National_GDB.zip\")\n",
    "\n",
    "wbd_dir = et.data.get_data(url=wbd_url)    # Path to downloaded file directory\n",
    "wbd_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 2-digit HU layer\n",
    "wbd_path = os.path.join(wbd_dir, 'WBD_National_GDB.gdb')    # Call gdb file\n",
    "gpd.read_file(wbd_path, layer='WBDHU2')             # Read in gdb and layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test plot to demonstrate successful import of data\n",
    "\n",
    "wbd_hu2_gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wildfire Dataset Description\n",
    "\n",
    "The wildfire data used in this analysis comes from the [USDA's wildfire occurance data for the United States, 1992-2020](https://www.fs.usda.gov/rds/archive/Catalog/RDS-2013-0009.6). This is the fifth version of the dataset and was generated from reporting systems of federal, state, and local fire organizations.\n",
    "\n",
    "Data Citation: \n",
    "Short, Karen C. 2022. Spatial wildfire occurrence data for the United States, 1992-2020 [FPA_FOD_20221014]. 6th Edition. Fort Collins, CO: Forest Service Research Data Archive. https://doi.org/10.2737/RDS-2013-0009.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download wildfire occurance data from geodatabase\n",
    "\n",
    "fire_url = (\n",
    "    \"https://www.fs.usda.gov/rds/archive/products/RDS-2013-0009.6\"\n",
    "    \"/RDS-2013-0009.6_Data_Format2_GDB.zip\"\n",
    ")\n",
    "\n",
    "fire_dir = et.data.get_data(url=fire_url)   # Path to downloaded fire directory\n",
    "fire_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import fires layer from geodatabase (cashing data)\n",
    "# Put import in an if statement to check if data already downloaded\n",
    "fire_path = os.path.join(fire_dir, 'Data','FPA_FOD_20221014.gdb')\n",
    "if not 'fire_gdf' in globals():\n",
    "    print('fire_gdf does not exist. Loading...')\n",
    "    fire_gdf = pyogrio.read_dataframe(fire_path, layer='Fires', from_disk=True)\n",
    "\n",
    "fire_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the data\n",
    "# Create an updated geodatabase, populating specific variables\n",
    "fire_clean_gdf = (\n",
    "    fire_gdf\n",
    "    [['FOD_ID', 'LATITUDE','LONGITUDE', DISCOVERY_DATE',\n",
    "      'NWCG_GENERAL_CAUSE', 'FIRE_SIZE']]\n",
    "    .set_index('FOD_ID')            # Set the index to a unique identifier\n",
    ")\n",
    "\n",
    "# Convert the existing date to a datetime format\n",
    "fire_clean_gdf.DISCOVERY_DATE = (\n",
    "  pd.to_datetime(fire_clean_gdf.DISCOVERY_DATE))\n",
    "\n",
    "# Reproject the dataframe to match the CRS of the watershed boundary\n",
    "fire_clean_gdf = fire_clean_gdf.to_crs(wbd_hu2_gdf.crs)\n",
    "fire_clean_gdf"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
